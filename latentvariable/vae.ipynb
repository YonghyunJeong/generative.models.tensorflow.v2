{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder with MNIST (or Fashion MNIST)\n",
    "\n",
    "* `Auto-Encoding Variational Bayes` [arXiv:1312.6114](https://arxiv.org/abs/1312.6114)\n",
    "  * Diederik P. Kingma and Max Welling\n",
    "\n",
    "* This code is available to tensorflow version 2.0\n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers) [`tf.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses)\n",
    "* This code refers to [TensorFlow official tutorial vae code](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/cvae.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/scpark/anaconda3/envs/ai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "from utils.image_utils import *\n",
    "from utils.ops import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'vae'\n",
    "train_dir = os.path.join('train', model_name, 'exp1')\n",
    "\n",
    "max_epochs = 100\n",
    "save_model_epochs = 5\n",
    "print_steps = 100\n",
    "save_images_epochs = 2\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "num_examples_to_generate = 16\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(-1, MNIST_SIZE, MNIST_SIZE, 1).astype('float32')\n",
    "train_images = train_images / 255.\n",
    "\n",
    "test_images = test_images.reshape(-1, MNIST_SIZE, MNIST_SIZE, 1).astype('float32')\n",
    "test_images = test_images / 255.\n",
    "\n",
    "# Binarization\n",
    "train_images[train_images >= .5] = 1.\n",
    "train_images[train_images < .5] = 0.\n",
    "test_images[test_images >= .5] = 1.\n",
    "test_images[test_images < .5] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>\n",
      "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(219)\n",
    "\n",
    "# for train\n",
    "N = len(train_images)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=N)\n",
    "test_dataset = test_dataset.batch(batch_size=num_examples_to_generate)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the AutoEncoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim=latent_dim):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.conv1 = Conv(32, 3, 2, padding='valid', apply_batchnorm=False)\n",
    "    self.conv2 = Conv(64, 3, 2, padding='valid', apply_batchnorm=False)\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.fc = layers.Dense(units=latent_dim * 2)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    x = self.conv1(inputs)\n",
    "    x = self.conv2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.fc = layers.Dense(units=7*7*32, activation='relu')\n",
    "    self.reshape = layers.Reshape(target_shape=(7, 7, 32))\n",
    "    self.conv1 = ConvTranspose(64, 3, 2, apply_batchnorm=False)\n",
    "    self.conv2 = ConvTranspose(32, 3, 2, apply_batchnorm=False)\n",
    "    self.conv3 = ConvTranspose(1, 3, 1, activation='none', apply_batchnorm=False)    \n",
    "    \n",
    "  def call(self, inputs):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    x = self.fc(inputs)\n",
    "    x = self.reshape(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "  \"\"\"Build a Variational Auto Encoder\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_dim=latent_dim):\n",
    "    super(VariationalAutoEncoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = Encoder(self.latent_dim)\n",
    "    self.decoder = Decoder()\n",
    "    \n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "  \n",
    "  def reparameterize(self, mean, logvar):\n",
    "    epsilon = tf.random.normal(shape=mean.shape)\n",
    "    return mean + tf.exp(logvar * .5) * epsilon\n",
    "  \n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.math.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  def sample(self, num_examples_to_generate=num_examples_to_generate, epsilon=None):\n",
    "    if epsilon is None:\n",
    "      epsilon = tf.random.normal(shape=(num_examples_to_generate, self.latent_dim))\n",
    "    return self.decode(epsilon, apply_sigmoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions and the optimizer\n",
    "\n",
    "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "In practice, we optimize the single sample Monte Carlo estimate of this expectation:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
    "where $z$ is sampled from $q(z|x)$.\n",
    "\n",
    "**Note**: we could also analytically compute the KL term, but here we incorporate all three terms in the Monte Carlo estimator for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal distribution**\n",
    "\n",
    "$$ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} \\exp \\left( {-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log normal distribution**\n",
    "\n",
    "$$ \\log \\mathcal{N}(\\mu, \\sigma) = -\\frac{1}{2} \\log(2 \\pi \\sigma^{2}) + \\left[ -\\frac{(x-\\mu)^{2}}{2\\sigma^{2}} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = -\\frac{1}{2} \\left[ \\log(2 \\pi) + \\log(\\sigma^{2}) + \\frac{(x-\\mu)^{2}}{\\sigma^{2}} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = -\\frac{1}{2} \\left[ \\log(2 \\pi) + \\log(\\sigma^{2}) + (x-\\mu)^{2} \\exp(\\log(-\\sigma^{2})) \\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return -.5 * tf.reduce_sum((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi, axis=raxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(inputs, logits, z, z_mean, z_logvar):\n",
    "  \"\"\"Calculate the VAE loss\n",
    "  reconstruction loss + KL divergence loss\n",
    "  for each dataset in minibatch.\n",
    "  Args:\n",
    "    inputs (4-rank T): input images (for target labels)\n",
    "    logits (4-rank T): logits of reconstructed images from P(X|z) for reconstruction loss\n",
    "    z_mean (1-rank T): Multi variate normal distribution parameters\n",
    "    z_logvar (1-rank T): Multi variate normal distribution parameters\n",
    "  Returns:\n",
    "    loss (0-rank T): reconstruction loss + KL divergence loss\n",
    "  \"\"\"\n",
    "  # reconstruction loss, $$\\log p(x| z)$$\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=inputs)\n",
    "  reconstructios_loss = -tf.reduce_sum(cross_ent, axis=[1, 2, 3]) # logpx_z\n",
    "\n",
    "  # KL Divergence D_KL( Q(z|X) || P(z|X) ),  $$\\log p(z) - \\log q(z|x)$$\n",
    "  #KL_loss = 0.5 * tf.reduce_sum(\n",
    "  #                    tf.exp(z_logvar) + z_mean**2 - 1. - z_logvar, 1)\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, z_mean, z_logvar)\n",
    "  KL_loss = logpz - logqz_x\n",
    "  return -tf.reduce_mean(reconstructios_loss + KL_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = train_dir\n",
    "if not tf.io.gfile.exists(checkpoint_dir):\n",
    "  tf.io.gfile.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, vae=vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "const_random_vector_for_saving = tf.random.normal([num_examples_to_generate, latent_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training one step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  with tf.GradientTape() as tape: \n",
    "    mean, logvar = vae.encode(images)\n",
    "    z = vae.reparameterize(mean, logvar)\n",
    "    x_logits = vae.decode(z)\n",
    "\n",
    "    loss = vae_loss(images, x_logits, z, mean, logvar)\n",
    "\n",
    "  gradients = tape.gradient(loss, vae.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "  \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train full steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7.46 global_step: 3500 loss: 103.677 (21466.25 examples/sec; 0.006 sec/batch)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Start Training.')\n",
    "num_batches_per_epoch = int(N / batch_size)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  \n",
    "  for step, images in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "      loss = train_step(images)\n",
    "      global_step.assign_add(1)\n",
    "    \n",
    "    if global_step.numpy() % print_steps == 0:\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = time.time() - start_time\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      display.clear_output(wait=True)\n",
    "      print(\"Epochs: {:.2f} global_step: {} loss: {:.3f} ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, global_step.numpy(), loss, examples_per_sec, duration))\n",
    "      sample_images = vae.sample(num_examples_to_generate)\n",
    "      \n",
    "      print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate)\n",
    "\n",
    "  if (epoch + 1) % save_images_epochs == 0:\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"This images are saved at {} epoch\".format(epoch+1))\n",
    "    sample_images = vae.sample(num_examples_to_generate, const_random_vector_for_saving)\n",
    "    print(sample_images.shape)\n",
    "    print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate,\n",
    "                                is_square=True, is_save=True, epoch=epoch+1,\n",
    "                                checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "  # saving (checkpoint) the model every save_epochs\n",
    "  if (epoch + 1) % save_model_epochs == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "print('Training Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating after the final epoch\n",
    "display.clear_output(wait=True)\n",
    "sample_images = vae.sample(num_examples_to_generate, const_random_vector_for_saving)\n",
    "print_or_save_sample_images(sample_images.numpy(), num_examples_to_generate,\n",
    "                                is_square=True, is_save=True, epoch=epoch+1,\n",
    "                                checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an image using the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(max_epochs, checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a GIF of all the saved images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = model_name + '_' + dataset_name + '.gif'\n",
    "generate_gif(filename, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.Image(filename=filename + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
