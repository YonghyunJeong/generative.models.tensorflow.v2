{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Visible Sigmoid Belief Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), _ = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data.reshape(-1, 784).astype('float32')\n",
    "#train_data = train_data / 255.\n",
    "# Change each pixel value from [0, 255] to [0, 1] using just one threshold (pixel mean)\n",
    "train_data_binary = np.heaviside(train_data - train_data.mean() * 3.0, 0.0)\n",
    "#train_labels = np.asarray(train_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 219\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "p = fig.add_subplot(1, 2, 1)\n",
    "p.imshow(train_data[index].reshape([28, 28]), cmap='gray')\n",
    "p.axis('off')\n",
    "\n",
    "p = fig.add_subplot(1, 2, 2)\n",
    "p.imshow(train_data_binary[index].reshape([28, 28]), cmap='gray')\n",
    "p.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`\n",
    "\n",
    "### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(219)\n",
    "\n",
    "# for train\n",
    "N = len(train_data_binary)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data_binary[:N])\n",
    "train_dataset = train_dataset.shuffle(buffer_size = N)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyVisibleSigmoidBeliefNetwork(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(FullyVisibleSigmoidBeliefNetwork, self).__init__()\n",
    "    self.models = []\n",
    "    self.init_pixel_probability = tf.contrib.eager.Variable(0.5)\n",
    "    for i in range(1, 784):\n",
    "      self.model = tf.keras.Sequential([layers.InputLayer(input_shape=[i]),\n",
    "                                        layers.Dense(units=1, activation='sigmoid')])\n",
    "      self.models.append(self.model)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    log_probability = tf.log(self.init_pixel_probability)\n",
    "    for i in range(1, 784):\n",
    "      log_probability += tf.log(self.models[i-1](inputs[:, 0:i]))\n",
    "      \n",
    "    return log_probability\n",
    "  \n",
    "  def sampling(self, num_samples):\n",
    "    samples = tf.contrib.eager.Variable(initial_value=tf.zeros([num_samples, 784], dtype=tf.int32))\n",
    "    samples[:, 0:1].assign(tf.transpose(\n",
    "                              tf.multinomial([[self.init_pixel_probability, 1.0 - self.init_pixel_probability]],\n",
    "                                             num_samples=num_samples, output_dtype=tf.int32)))\n",
    "    for i in range(1, 784):\n",
    "      probability_ith_pixel = self.models[i-1](tf.cast(samples[:, 0:i], dtype=tf.float32)).numpy() # actually i+1 th pixel\n",
    "      samples[:, i:i+1].assign(tf.multinomial(tf.concat((probability_ith_pixel, 1.0 - probability_ith_pixel), axis=1),\n",
    "                                              num_samples=1, output_dtype=tf.int32))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvsbn = FullyVisibleSigmoidBeliefNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info('Start Training.')\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "for epoch in range(10):\n",
    "  \n",
    "  for images in train_dataset:\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      log_likelihood = fvsbn(images)\n",
    "      loss = -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "    gradients = tape.gradient(loss, fvsbn.variables)\n",
    "    optimizer.apply_gradients(zip(gradients, fvsbn.variables), global_step=global_step)\n",
    "    \n",
    "    epochs = global_step.numpy() * batch_size / float(N)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    print_steps = 1\n",
    "    if global_step.numpy() % print_steps == 0:\n",
    "      display.clear_output(wait=True)\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      print(\"Epochs: {:.2f} global_step: {} loss: {:.3f} ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, global_step.numpy(), loss.numpy(), examples_per_sec, duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fvsbn.sampling(2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 2))\n",
    "p = fig.add_subplot(1, 2, 1)\n",
    "p.imshow(samples[0].reshape([28, 28]), cmap='gray')\n",
    "p.axis('off')\n",
    "\n",
    "p = fig.add_subplot(1, 2, 2)\n",
    "p.imshow(samples[1].reshape([28, 28]), cmap='gray')\n",
    "p.axis('off')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
